{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:29:06.774154Z",
     "start_time": "2022-05-23T13:28:59.436103Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "device = 'cpu'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "seed = 42069\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:29:30.212970Z",
     "start_time": "2022-05-23T13:29:06.781710Z"
    }
   },
   "outputs": [],
   "source": [
    "train_file = 'train_features.csv'\n",
    "train_lab_file = 'train_labels.csv'\n",
    "df_x_train = pd.read_csv(train_file)\n",
    "df_y_train = pd.read_csv(train_lab_file).iloc[:,-1]\n",
    "\n",
    "pretrain_file = 'pretrain_features.csv'\n",
    "pretrain_lab_file = 'pretrain_labels.csv'\n",
    "df_x_pretrain = pd.read_csv(pretrain_file)\n",
    "df_y_pretrain = pd.read_csv(pretrain_lab_file).iloc[:,-1]\n",
    "\n",
    "test_file = 'test_features.csv'\n",
    "df_x_test = pd.read_csv(test_file)\n",
    "\n",
    "df_features = pd.concat([df_x_pretrain,df_x_train,df_x_test]).iloc[:,2:]\n",
    "# delete features with constants\n",
    "df_features = df_features.loc[:, (df_features != 1).any(axis=0)]\n",
    "df_features = df_features.loc[:, (df_features != 0).any(axis=0)]\n",
    "selected_features = df_features.columns\n",
    "df_test_index = df_x_test['Id']\n",
    "df_x_pretrain = df_x_pretrain[selected_features]\n",
    "df_x_train = df_x_train[selected_features]\n",
    "df_x_test = df_x_test[selected_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:29:30.574924Z",
     "start_time": "2022-05-23T13:29:30.218031Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrain_x_t = torch.tensor(df_x_pretrain.values).float().to(device)\n",
    "pretrain_y_t = torch.tensor(df_y_pretrain.values).float().to(device)\n",
    "# normalize output data\n",
    "pre_y_mean = torch.mean(pretrain_y_t)\n",
    "pre_y_std = torch.std(pretrain_y_t)\n",
    "pretrain_y_norm_t = (pretrain_y_t-pre_y_mean)/(pre_y_std+1e-5)\n",
    "\n",
    "pretrain_x_feature_t = pretrain_x_t\n",
    "\n",
    "pretrain_ds = torch.utils.data.TensorDataset(pretrain_x_feature_t, pretrain_y_norm_t)\n",
    "#split into train and validation set\n",
    "pretrain_size = int(0.8 * len(pretrain_ds))\n",
    "prevalid_size = len(pretrain_ds) - pretrain_size\n",
    "pretrain_ds, pretrain_valid_ds = torch.utils.data.random_split(pretrain_ds,[pretrain_size,prevalid_size])\n",
    "pretrain_loader = torch.utils.data.DataLoader(pretrain_ds, batch_size=128, shuffle=True)\n",
    "prevalid_loader = torch.utils.data.DataLoader(pretrain_valid_ds, batch_size=10001, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:29:30.642361Z",
     "start_time": "2022-05-23T13:29:30.583166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488501 parameters\n",
      "1 hidden layers\n"
     ]
    }
   ],
   "source": [
    "class lumo_predictor(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__() \n",
    "\n",
    "        layer_seq = [input_dim,500]\n",
    "        self.reg_layer = torch.nn.Linear(500,1)\n",
    "        self.do_regress = True\n",
    "              \n",
    "        num_layer = len(layer_seq)-1\n",
    "        layer_fc = [None]*num_layer\n",
    "        \n",
    "        num_param=500+1\n",
    "        \n",
    "        for i in range(num_layer):\n",
    "            layer_fc[i] = torch.nn.Linear(layer_seq[i],layer_seq[i+1])\n",
    "            num_param +=(layer_seq[i]+1)*layer_seq[i+1]\n",
    "        print(f\"{num_param} parameters\")\n",
    "        print(f\"{num_layer} hidden layers\")\n",
    "        \n",
    "        self.layer_fc = torch.nn.ModuleList(layer_fc)\n",
    "        self.activation_fn = torch.nn.ReLU()\n",
    "        self.dropout_hid = torch.nn.Dropout(0.1)\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result = x\n",
    "        for func in self.layer_fc:\n",
    "            result = func(result)\n",
    "            result = self.activation_fn(result)\n",
    "            result = self.dropout_hid(result)\n",
    "        if self.do_regress:\n",
    "            result = self.reg_layer(result)\n",
    "        \n",
    "        return result\n",
    "            \n",
    "model = lumo_predictor(pretrain_x_feature_t.shape[1]).to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:31:23.998650Z",
     "start_time": "2022-05-23T13:29:42.379648Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:tensor([-3.6573, -3.5196, -4.1616, -3.0519, -3.0425, -3.0426, -3.1657, -2.8293])\n",
      "actual:   tensor([-3.7025, -3.6878, -4.0376, -3.0299, -3.1004, -2.7587, -3.3262, -2.7418])\n",
      "Epoch 0 | Train loss: 0.2643 | verif loss: 0.1229\n",
      "predicted:tensor([-3.5114, -3.3087, -3.7808, -3.4855, -3.9178, -3.4424, -3.6918, -3.3689])\n",
      "actual:   tensor([-3.4710, -3.4436, -4.0092, -3.3869, -3.9373, -3.5650, -3.7813, -3.4592])\n",
      "Epoch 1 | Train loss: 0.0828 | verif loss: 0.1034\n",
      "predicted:tensor([-3.2908, -2.8637, -3.8747, -2.8474, -2.8535, -3.3317, -2.9391, -3.0289])\n",
      "actual:   tensor([-3.2077, -2.8636, -3.6948, -2.8012, -2.8783, -3.3338, -2.7123, -3.1293])\n",
      "Epoch 2 | Train loss: 0.0635 | verif loss: 0.0945\n",
      "predicted:tensor([-3.4509, -3.0825, -3.8961, -2.8301, -3.6790, -4.0233, -3.1661, -3.4717])\n",
      "actual:   tensor([-3.4506, -3.0140, -3.9731, -2.9336, -3.7103, -3.9692, -3.1077, -3.5771])\n",
      "Epoch 3 | Train loss: 0.0534 | verif loss: 0.0882\n",
      "predicted:tensor([-3.6085, -3.0946, -3.7560, -3.1289, -3.0631, -2.7868, -3.3014, -3.5190])\n",
      "actual:   tensor([-3.5970, -2.8401, -3.7265, -3.1513, -3.0015, -2.7912, -3.2671, -3.5153])\n",
      "Epoch 4 | Train loss: 0.0458 | verif loss: 0.0828\n",
      "predicted:tensor([-3.2783, -2.8057, -3.2427, -2.5653, -3.4791, -3.8305, -3.0115, -3.7549])\n",
      "actual:   tensor([-3.3382, -2.9547, -3.2315, -2.5829, -3.5735, -3.8506, -2.9991, -3.7264])\n",
      "Epoch 5 | Train loss: 0.0398 | verif loss: 0.0782\n",
      "Saved model checkpoint to model_lumo_epoch_5.pt\n",
      "predicted:tensor([-3.5211, -4.0711, -3.3750, -2.9374, -2.9705, -3.3278, -3.0774, -3.3329])\n",
      "actual:   tensor([-3.4805, -4.0164, -3.6482, -2.9842, -3.0398, -3.2762, -3.0944, -3.3109])\n",
      "Epoch 6 | Train loss: 0.0346 | verif loss: 0.0754\n",
      "predicted:tensor([-3.1464, -3.0001, -3.4765, -3.0807, -3.3756, -3.6558, -3.9516, -3.8365])\n",
      "actual:   tensor([-3.1356, -2.9211, -3.4902, -3.0674, -3.4325, -3.8032, -3.9104, -3.8304])\n",
      "Epoch 7 | Train loss: 0.0305 | verif loss: 0.0707\n",
      "predicted:tensor([-3.2334, -3.9259, -3.3645, -4.1084, -3.0727, -3.3548, -2.3818, -3.0675])\n",
      "actual:   tensor([-3.1759, -3.9237, -3.4023, -4.0244, -3.0520, -3.4291, -2.4668, -3.1117])\n",
      "Epoch 8 | Train loss: 0.0271 | verif loss: 0.0680\n",
      "predicted:tensor([-3.4991, -2.6339, -3.8814, -3.5324, -3.0093, -3.2895, -3.5447, -3.1692])\n",
      "actual:   tensor([-3.5581, -2.6000, -3.8648, -3.5936, -2.9869, -3.1834, -3.5374, -3.2179])\n",
      "Epoch 9 | Train loss: 0.0243 | verif loss: 0.0658\n",
      "predicted:tensor([-2.8108, -2.8994, -2.8600, -3.9574, -3.1550, -3.8209, -2.9229, -2.9949])\n",
      "actual:   tensor([-2.7531, -2.8636, -2.8325, -3.9796, -3.2127, -3.8314, -2.9476, -3.0603])\n",
      "Epoch 10 | Train loss: 0.0219 | verif loss: 0.0636\n",
      "Saved model checkpoint to model_lumo_epoch_10.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) :\n",
    "    # goes through the test dataset and computes the test accuracy\n",
    "    model.eval()  # bring the model into eval mode\n",
    "    with torch.no_grad():\n",
    "        loss_cum = 0.0\n",
    "        num_eval_samples = 0\n",
    "        \n",
    "        for x_batch, y_batch in prevalid_loader:\n",
    "            output = model(x_batch).flatten()*pre_y_std+pre_y_mean\n",
    "            y_batch = y_batch*pre_y_std+pre_y_mean\n",
    "            batch_size = output.shape[0]\n",
    "            \n",
    "            print(f\"predicted:{output[:8]}\")\n",
    "            print(f\"actual:   {y_batch[:8]}\")\n",
    "            num_eval_samples += batch_size\n",
    "            loss_batch = loss_func(output, y_batch)\n",
    "            loss_cum += loss_batch * batch_size\n",
    "            \n",
    "        avg_loss = loss_cum / num_eval_samples\n",
    "        return torch.sqrt(avg_loss)\n",
    "            \n",
    "        \n",
    "for epoch in range(11):\n",
    "    # reset statistics trackers\n",
    "    train_loss_cum = 0.0\n",
    "    num_samples_epoch = 0\n",
    "    num_errors = 0\n",
    "    for x_batch, y_batch in pretrain_loader:\n",
    "        # zero grads and put model into train mode\n",
    "        optim.zero_grad()\n",
    "        model.train()\n",
    "        # forward pass\n",
    "        output = model(x_batch).flatten()\n",
    "        loss = loss_func(output, y_batch)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # keep track of train stats\n",
    "        num_samples_batch = output.shape[0]\n",
    "        num_samples_epoch += num_samples_batch\n",
    "        train_loss_cum += loss * num_samples_batch\n",
    "            \n",
    "    # average the accumulated statistics\n",
    "    avg_train_loss = train_loss_cum / num_samples_epoch\n",
    "    verif_loss = evaluate(model)\n",
    "\n",
    "    # print some infos\n",
    "    print(f'Epoch {epoch} | Train loss: {avg_train_loss:.4f} | verif rms: {verif_loss:.4f}')\n",
    "    # save checkpoint of model\n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        save_path = f'model_lumo_epoch_{epoch}.pt'\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optim.state_dict()},\n",
    "                    save_path)\n",
    "        print(f'Saved model checkpoint to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T12:21:35.102855Z",
     "start_time": "2022-05-23T12:21:35.048452Z"
    }
   },
   "outputs": [],
   "source": [
    "def reload_model(number):\n",
    "    previous_run = torch.load(f'./model_lumo_epoch_{number}.pt')\n",
    "    model.load_state_dict(previous_run['model_state_dict'])\n",
    "    optim.load_state_dict(previous_run['optimizer_state_dict'])\n",
    "reload_model(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:31:32.385043Z",
     "start_time": "2022-05-23T13:31:32.070037Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x_t = torch.tensor(df_x_train.values).float().to(device)\n",
    "train_y_t = torch.tensor(df_y_train.values).float().to(device)\n",
    "\n",
    "\n",
    "test_t = torch.tensor(df_x_test.values).float().to(device)\n",
    "\n",
    "model.eval()\n",
    "model.do_regress = False\n",
    "\n",
    "with torch.no_grad():    \n",
    "    train_x_feature_t = model(train_x_t)\n",
    "    test_feature_t = model(test_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:31:44.458011Z",
     "start_time": "2022-05-23T13:31:38.397500Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:06<00:00,  8.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.20249552, 0.20249537, 0.20249533, 0.20249526, 0.20249518,\n",
       "       0.20249507, 0.20249493, 0.20249474, 0.20249449, 0.20249415,\n",
       "       0.20249371, 0.20249312, 0.20249234, 0.20249131, 0.20248994,\n",
       "       0.20248813, 0.20248574, 0.20248258, 0.20247841, 0.20247291,\n",
       "       0.20246568, 0.20245619, 0.20244379, 0.20242765, 0.20240678,\n",
       "       0.20238   , 0.20234605, 0.20230368, 0.20225195, 0.20219075,\n",
       "       0.20212172, 0.20204963, 0.2019844 , 0.20194385, 0.20195688,\n",
       "       0.2020668 , 0.20233402, 0.20283733, 0.20367353, 0.20495549,\n",
       "       0.20680955, 0.2099286 , 0.21558562, 0.22261083, 0.23115837,\n",
       "       0.24132914, 0.25313963, 0.26650341, 0.28123489, 0.29707681,\n",
       "       0.313745  ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [0,*np.logspace(-5,1)]\n",
    "models = [linear_model.Ridge(alpha=alpha) for alpha in alphas]\n",
    "rms_loss = [-cross_val_score(model, train_x_feature_t, train_y_t, scoring='neg_root_mean_squared_error', n_jobs=2, cv=10) for model in tqdm(models)]\n",
    "max_loss = np.max(rms_loss,axis = 1)\n",
    "max_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:32:04.171198Z",
     "start_time": "2022-05-23T13:32:03.951463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.08286427728546843, rms=0.20194384790260664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1.7\n",
       "1    2.2\n",
       "2    1.7\n",
       "3    2.4\n",
       "4    1.6\n",
       "5    1.6\n",
       "6    2.1\n",
       "7    2.3\n",
       "8    1.8\n",
       "9    1.6\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.argmin(max_loss)\n",
    "print(f\"alpha={alphas[index]}, rms={np.min(max_loss)}\")\n",
    "reg = models[index]\n",
    "reg.fit(train_x_feature_t,train_y_t)\n",
    "answer = reg.predict(test_feature_t)\n",
    "\n",
    "sol = pd.DataFrame(df_test_index,columns=['Id'])\n",
    "sol.insert(1, 'y', np.around(answer,decimals=1))\n",
    "sol.to_csv(\"submission.csv\",index=False,float_format='%.1f')\n",
    "sol['y'].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
