{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67anfy1-hxZr",
        "outputId": "0904f6b2-cced-4e2f-c0f5-f9960ebab83c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "#files from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from torchvision import transforms, datasets\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "seed = 42069\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I3OAamgRlMKY"
      },
      "outputs": [],
      "source": [
        "# create triplets id data frame\n",
        "#for submission\n",
        "test_triplet_file = 'drive/MyDrive/IML/test_triplets.txt'\n",
        "test_triplet = pd.read_csv(test_triplet_file, sep=' ', names=['A','B','C'], header=None, dtype = str)\n",
        "\n",
        "#train set\n",
        "test_triplet_file = 'drive/MyDrive/IML/train_triplets.txt'\n",
        "df = pd.read_csv(test_triplet_file, sep=' ', names=['A','B','C'], header=None, dtype = str)\n",
        "df = shuffle(df,random_state=seed)\n",
        "\n",
        "#split into training and validation triplets\n",
        "train_size=int(len(df)*0.9)\n",
        "train_triplet = df.iloc[:train_size]\n",
        "\n",
        "# reverse half of the validation set\n",
        "half_valid_size= int((len(df)-train_size)/2)\n",
        "validation_triplet = df.iloc[train_size:]\n",
        "\n",
        "valid_triplet_reverse = validation_triplet.iloc[half_valid_size:]\n",
        "valid_triplet_reverse = pd.DataFrame({'A':valid_triplet_reverse['A'],'B':valid_triplet_reverse['C'],\n",
        "                                      'C':valid_triplet_reverse['B'],'Label': np.zeros((half_valid_size,))})\n",
        "\n",
        "valid_triplet_ordered = validation_triplet.iloc[:half_valid_size]\n",
        "valid_triplet_ordered.insert(loc=3, column='Label', value=np.ones((valid_triplet_ordered.shape[0],)))\n",
        "\n",
        "valid_triplet = shuffle(pd.concat([valid_triplet_reverse, valid_triplet_ordered]),random_state=seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWqyyaXlly7h"
      },
      "source": [
        "## Apply pre-trained CNN to images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9vOoOH_ZiMZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "bddf86622ded4d0fad085db49c518c70",
            "75c86deaf9744b9e9bf7d8f07f3639fb",
            "b98216aa90cf47dfa4d8163a3322632e",
            "f64f8f58f86f42cd9451b8df3d05797e",
            "40b9df9482a84a86ab12cf256dab3dd0",
            "0684ef0be24b40008f779ce53ee2003a",
            "8b792a596d544ade92a190bb9ef4c133",
            "a20b6b49e7244e139071fca870f00892",
            "e1c329664b6946348560cd1fe51eef92",
            "2dcc4e5dee0d4ce685ecc46eedb68d39",
            "53f1ddaee9a3483796083214ad169e77"
          ]
        },
        "outputId": "b912e7e4-10b8-4e2c-abe8-62f069f0cd65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bddf86622ded4d0fad085db49c518c70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10001/10001 [04:36<00:00, 36.11it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "food_processed_dict = {}\n",
        "\n",
        "import pickle\n",
        "#read dict from file\n",
        "save_file = \"drive/MyDrive/IML/dict_food_preprocessed_50.pkl\"\n",
        "is_file_valid = False\n",
        "\n",
        "#open if features dictionary alredy exist\n",
        "if os.path.exists(save_file):\n",
        "    file_dict = open(save_file,\"rb\")\n",
        "    food_processed_dict = pickle.load(file_dict)\n",
        "    file_dict.close()\n",
        "    is_file_valid = len(food_processed_dict) == 1000\n",
        "\n",
        "#extract features if they don't exist\n",
        "if not os.path.exists(save_file) or not is_file_valid:\n",
        "\n",
        "    import zipfile\n",
        "    # Open .zip archive\n",
        "    zip_folder = 'drive/MyDrive/food.zip'\n",
        "    zip_ref = zipfile.ZipFile(zip_folder, 'r')\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()\n",
        "\n",
        "    from PIL import Image\n",
        "    #use pretrained CNN to extract features of the images\n",
        "    model_CNN = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "    model_CNN.to(device)\n",
        "    model_CNN.fc = torch.nn.Identity()\n",
        "    model_CNN.eval()\n",
        "\n",
        "    reshape = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    def preprocess_image(image_path) :\n",
        "      img = Image.open(image_path)\n",
        "      input_tensor = reshape(img)\n",
        "      input_batch = input_tensor.unsqueeze(0).to(device)\n",
        "      with torch.no_grad():\n",
        "          return model_CNN(input_batch).to('cpu')\n",
        "    \n",
        "    directory = 'food'\n",
        "    \n",
        "    # iterate over files \n",
        "    for filename in tqdm(os.listdir(directory)):\n",
        "      img_path = os.path.join(directory, filename)\n",
        "      # checking if it is a .jpg file\n",
        "      if os.path.isfile(img_path) and (filename[-4:]==\".jpg\"):\n",
        "        out = preprocess_image(img_path)\n",
        "        food_processed_dict[filename[:-4]] = out\n",
        "\n",
        "    #save dictionary to file\n",
        "    file_dict = open(save_file,\"wb\")\n",
        "    pickle.dump(food_processed_dict,file_dict)\n",
        "\n",
        "    file_dict.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPR0w3p6lCkP"
      },
      "source": [
        "## Fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlVHkjKLZzeq",
        "outputId": "e1a07061-5985-481a-bd7d-6ffc2b0a39f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading verification triplets : \n",
            "Index(['A', 'B', 'C', 'Label'], dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5952/5952 [00:05<00:00, 1060.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train triplets : \n",
            "Index(['A', 'B', 'C'], dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 53563/53563 [00:36<00:00, 1453.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test triplets : \n",
            "Index(['A', 'B', 'C'], dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 59544/59544 [00:37<00:00, 1592.28it/s]\n"
          ]
        }
      ],
      "source": [
        "def load_triplet_features(triplet,key):\n",
        "    tensor = food_processed_dict[triplet[key]].flatten()\n",
        "    return tensor.unsqueeze(0).to(device)\n",
        "\n",
        "def load_triplet_to_torch(triplets):\n",
        "      A_tensor_arr = [None] * len(triplets)\n",
        "      B_tensor_arr = [None] * len(triplets)\n",
        "      C_tensor_arr = [None] * len(triplets)\n",
        "\n",
        "      if 'Label' in triplets.columns:\n",
        "        labels_arr = [None] * len(triplets)\n",
        "\n",
        "      for i in tqdm(range(len(triplets))):\n",
        "          A_tensor_arr[i] = load_triplet_features(triplets.iloc[i],'A')\n",
        "          B_tensor_arr[i] = load_triplet_features(triplets.iloc[i],'B')\n",
        "          C_tensor_arr[i] = load_triplet_features(triplets.iloc[i],'C')\n",
        "          if 'Label' in triplets.columns:\n",
        "            labels_arr[i] = torch.full((1,),triplets['Label'].iloc[i]).unsqueeze(0)\n",
        "\n",
        "      A_tensor_t = torch.cat(A_tensor_arr)\n",
        "      B_tensor_t = torch.cat(B_tensor_arr)\n",
        "      C_tensor_t = torch.cat(C_tensor_arr)\n",
        "      if 'Label' in triplets.columns:\n",
        "        label_t = torch.cat(labels_arr)\n",
        "        return torch.utils.data.TensorDataset(A_tensor_t, B_tensor_t, C_tensor_t, label_t)\n",
        "\n",
        "      else:\n",
        "        return torch.utils.data.TensorDataset(A_tensor_t, B_tensor_t, C_tensor_t)\n",
        "\n",
        "print(\"Loading verification triplets : \")\n",
        "verif_ds = load_triplet_to_torch(valid_triplet)\n",
        "verif_loader = torch.utils.data.DataLoader(verif_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"Loading train triplets : \")\n",
        "train_ds = load_triplet_to_torch(train_triplet)\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"Loading test triplets : \")\n",
        "test_ds = load_triplet_to_torch(test_triplet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GxcmQ37hm-CU"
      },
      "outputs": [],
      "source": [
        "class FullyConnectedLayers(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim: int):\n",
        "    super().__init__() \n",
        "\n",
        "    self.fc1 = torch.nn.Linear(input_dim, 512) \n",
        "    self.fc2 = torch.nn.Linear(512, 82)\n",
        "    self.fc3 = torch.nn.Linear(82,8)\n",
        "    \n",
        "    self.dropout = torch.nn.Dropout()\n",
        "    self.activation_fn = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    \n",
        "    result = self.dropout(x)\n",
        "    result = self.fc1(result)\n",
        "    result = self.activation_fn(result)\n",
        "    result = self.fc2(result)\n",
        "    result = self.activation_fn(result)\n",
        "    result = self.fc3(result)\n",
        "    \n",
        "    return result\n",
        "    \n",
        "\n",
        "in_size = food_processed_dict[list(food_processed_dict.keys())[0]].shape[1]\n",
        "model_fc = FullyConnectedLayers(in_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MswUrRwQ2DSC"
      },
      "outputs": [],
      "source": [
        "optim = torch.optim.Adam(model_fc.parameters(),lr=0.0001)\n",
        "lp_norm = 1\n",
        "loss_func = torch.nn.TripletMarginLoss(margin=1, p=lp_norm, eps=1e-06, swap=False, \n",
        "                                       size_average=None, reduce=None, reduction='mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jkDhwp7YQ8Sb"
      },
      "outputs": [],
      "source": [
        "#get label from the output of the network\n",
        "def get_label(anchor, positive, negative):\n",
        "  dist_p = torch.Tensor.norm(anchor-positive,p=lp_norm,dim=-1)\n",
        "  dist_n = torch.Tensor.norm(anchor-negative,p=lp_norm,dim=-1)\n",
        "  \n",
        "  return dist_p < dist_n\n",
        "\n",
        "def accuracy(anchor, positive, negative, labels) -> torch.Tensor:\n",
        "  # computes the classification accuracy\n",
        "  result = get_label(anchor, positive, negative)\n",
        "  total_num = result.shape[0]\n",
        "  correct_num = (result.flatten() == labels).sum().item()\n",
        "  acc = correct_num / total_num\n",
        "  \n",
        "  assert 0. <= acc <= 1.\n",
        "  return acc\n",
        "\n",
        "\n",
        "def evaluate(model: torch.nn.Module) -> torch.Tensor:\n",
        "  # goes through the test dataset and computes the test accuracy\n",
        "  model.eval()  # bring the model into eval mode\n",
        "  with torch.no_grad():\n",
        "    acc_cum = 0.0\n",
        "    num_eval_samples = 0\n",
        "    for anchor_verif, positive_verif, negative_verif, labels in verif_loader:\n",
        "      anc_emb = model(anchor_verif)      \n",
        "      pos_emb = model(positive_verif)\n",
        "      neg_emb = model(negative_verif)\n",
        "      labels = labels.to(device)\n",
        "      batch_size = pos_emb.shape[0]\n",
        "      num_eval_samples += batch_size\n",
        "    \n",
        "      acc_cum += accuracy(anc_emb,pos_emb,neg_emb,labels.flatten()) * batch_size\n",
        "      \n",
        "    avg_acc = acc_cum / num_eval_samples\n",
        "    assert 0 <= avg_acc <= 1\n",
        "    return avg_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0u0ytwGjr-L",
        "outputId": "97705e53-5cbd-404b-d5ac-5f6db9406c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train loss: 38.1206, Validation accuracy: 0.7144\n",
            "Epoch 1, Train loss: 35.7228, Validation accuracy: 0.7320\n",
            "Epoch 2, Train loss: 34.5390, Validation accuracy: 0.7382\n",
            "Epoch 3, Train loss: 33.5637, Validation accuracy: 0.7463\n",
            "Epoch 4, Train loss: 32.6379, Validation accuracy: 0.7520\n",
            "Epoch 5, Train loss: 31.8779, Validation accuracy: 0.7586\n",
            "Saved model checkpoint to model_epoch_5.pt\n",
            "Epoch 6, Train loss: 31.2537, Validation accuracy: 0.7613\n",
            "Epoch 7, Train loss: 30.3728, Validation accuracy: 0.7670\n",
            "Epoch 8, Train loss: 29.8895, Validation accuracy: 0.7702\n",
            "Epoch 9, Train loss: 29.1462, Validation accuracy: 0.7742\n",
            "Epoch 10, Train loss: 28.7586, Validation accuracy: 0.7846\n",
            "Saved model checkpoint to model_epoch_10.pt\n",
            "Epoch 11, Train loss: 28.0260, Validation accuracy: 0.7868\n",
            "Epoch 12, Train loss: 27.6269, Validation accuracy: 0.7891\n",
            "Epoch 13, Train loss: 26.8853, Validation accuracy: 0.7969\n",
            "Epoch 14, Train loss: 26.3903, Validation accuracy: 0.7962\n",
            "Epoch 15, Train loss: 25.7514, Validation accuracy: 0.7960\n",
            "Saved model checkpoint to model_epoch_15.pt\n",
            "Epoch 16, Train loss: 25.5014, Validation accuracy: 0.8044\n",
            "Epoch 17, Train loss: 25.0379, Validation accuracy: 0.8051\n",
            "Epoch 18, Train loss: 24.6461, Validation accuracy: 0.8096\n",
            "Epoch 19, Train loss: 24.3614, Validation accuracy: 0.8085\n",
            "Epoch 20, Train loss: 23.8643, Validation accuracy: 0.8100\n",
            "Saved model checkpoint to model_epoch_20.pt\n",
            "Epoch 21, Train loss: 23.4454, Validation accuracy: 0.8133\n",
            "Epoch 22, Train loss: 23.2090, Validation accuracy: 0.8100\n",
            "Epoch 23, Train loss: 22.9370, Validation accuracy: 0.8107\n",
            "Epoch 24, Train loss: 22.4556, Validation accuracy: 0.8182\n",
            "Epoch 25, Train loss: 22.1294, Validation accuracy: 0.8226\n",
            "Saved model checkpoint to model_epoch_25.pt\n",
            "Epoch 26, Train loss: 21.8142, Validation accuracy: 0.8239\n",
            "Epoch 27, Train loss: 21.3802, Validation accuracy: 0.8234\n",
            "Epoch 28, Train loss: 21.0739, Validation accuracy: 0.8231\n",
            "Epoch 29, Train loss: 20.7399, Validation accuracy: 0.8281\n",
            "Epoch 30, Train loss: 20.6331, Validation accuracy: 0.8359\n",
            "Saved model checkpoint to model_epoch_30.pt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(31):\n",
        "  # reset statistics trackers\n",
        "  train_loss_cum = 0.0\n",
        "  acc_cum = 0.0\n",
        "  num_samples_epoch = 0\n",
        "  \n",
        "  for anchor, positive, negative in train_loader:\n",
        "      # zero grads and put model into train mode\n",
        "      optim.zero_grad()\n",
        "      model_fc.train()\n",
        "      # forward pass\n",
        "      pos_emb = model_fc(positive)\n",
        "      anc_emb = model_fc(anchor)\n",
        "      neg_emb = model_fc(negative)\n",
        "      loss = loss_func(anc_emb, pos_emb, neg_emb)\n",
        "      # backward pass\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "\n",
        "      # keep track of train stats\n",
        "      num_samples_batch = positive.shape[0]\n",
        "      num_samples_epoch += num_samples_batch\n",
        "      train_loss_cum += loss / num_samples_batch\n",
        "  \n",
        "  # average the accumulated statistics\n",
        "  avg_train_loss = train_loss_cum / num_samples_epoch\n",
        "  valid_acc = evaluate(model_fc)\n",
        "  \n",
        "  # print some infos\n",
        "  print(f'Epoch {epoch}, Train loss: {train_loss_cum:.4f}, Validation accuracy: {valid_acc:.4f}' )\n",
        "  # save checkpoint of model\n",
        "  if epoch % 5 == 0 and epoch > 0:\n",
        "      save_path = f'model_epoch_{epoch}.pt'\n",
        "      torch.save({'epoch': epoch,\n",
        "                  'model_state_dict': model_fc.state_dict(),\n",
        "                  'optimizer_state_dict': optim.state_dict()},\n",
        "                 save_path)\n",
        "      print(f'Saved model checkpoint to {save_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "En-rlQcG7DH7"
      },
      "outputs": [],
      "source": [
        "def reload_model(number):\n",
        "    previous_run = torch.load(f'./model_epoch_{number}.pt')\n",
        "    previous_run['model_state_dict']\n",
        "    model_fc.load_state_dict(previous_run['model_state_dict'])\n",
        "    optim.load_state_dict(previous_run['optimizer_state_dict'])\n",
        "reload_model(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VCAKvTGzGkpQ"
      },
      "outputs": [],
      "source": [
        "model_fc.eval()  # bring the model into eval mode\n",
        "test_loader = torch.utils.data.DataLoader(test_ds,batch_size=59544,shuffle=False)\n",
        "with torch.no_grad():\n",
        "  for anchor, positive, negative in test_loader:\n",
        "    pos_emb = model_fc(positive)\n",
        "    anc_emb = model_fc(anchor)\n",
        "    neg_emb = model_fc(negative)\n",
        "  \n",
        "    submission = get_label(anc_emb,pos_emb,neg_emb)\n",
        "answer = submission.flatten().to('cpu').numpy().astype(int)\n",
        "#write to file \n",
        "pd.DataFrame(answer).transpose().to_csv(\"submission.txt\",index=False,header=False,sep='\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "triplet_Task3_clean.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bddf86622ded4d0fad085db49c518c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75c86deaf9744b9e9bf7d8f07f3639fb",
              "IPY_MODEL_b98216aa90cf47dfa4d8163a3322632e",
              "IPY_MODEL_f64f8f58f86f42cd9451b8df3d05797e"
            ],
            "layout": "IPY_MODEL_40b9df9482a84a86ab12cf256dab3dd0"
          }
        },
        "75c86deaf9744b9e9bf7d8f07f3639fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0684ef0be24b40008f779ce53ee2003a",
            "placeholder": "​",
            "style": "IPY_MODEL_8b792a596d544ade92a190bb9ef4c133",
            "value": "100%"
          }
        },
        "b98216aa90cf47dfa4d8163a3322632e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a20b6b49e7244e139071fca870f00892",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1c329664b6946348560cd1fe51eef92",
            "value": 102530333
          }
        },
        "f64f8f58f86f42cd9451b8df3d05797e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dcc4e5dee0d4ce685ecc46eedb68d39",
            "placeholder": "​",
            "style": "IPY_MODEL_53f1ddaee9a3483796083214ad169e77",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 113MB/s]"
          }
        },
        "40b9df9482a84a86ab12cf256dab3dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0684ef0be24b40008f779ce53ee2003a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b792a596d544ade92a190bb9ef4c133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a20b6b49e7244e139071fca870f00892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c329664b6946348560cd1fe51eef92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dcc4e5dee0d4ce685ecc46eedb68d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f1ddaee9a3483796083214ad169e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}